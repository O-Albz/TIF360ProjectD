{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f3a8dbe",
   "metadata": {},
   "source": [
    "# pls work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afec3497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9304a8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1s/z220kbn525j9yjx9gm24pbv40000gn/T/ipykernel_99636/2505249569.py:4: DtypeWarning: Columns (0,1,5,6,8,12,18,20,21,22,24,33,34,38,39,44,47,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_labelconvertion = pd.read_csv('fma_metadata/tracks.csv', index_col=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>genre_top</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106571</th>\n",
       "      <td>155316</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106572</th>\n",
       "      <td>155317</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106573</th>\n",
       "      <td>155318</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106574</th>\n",
       "      <td>155319</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106575</th>\n",
       "      <td>155320</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106574 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       track_id genre_top\n",
       "2             2   Hip-Hop\n",
       "3             3   Hip-Hop\n",
       "4             5   Hip-Hop\n",
       "5            10       Pop\n",
       "6            20     Other\n",
       "...         ...       ...\n",
       "106571   155316      Rock\n",
       "106572   155317      Rock\n",
       "106573   155318      Rock\n",
       "106574   155319      Rock\n",
       "106575   155320     Other\n",
       "\n",
       "[106574 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import the csv file\n",
    "df_labelconvertion = pd.read_csv('fma_metadata/tracks.csv', index_col=1)\n",
    "\n",
    "# rename columns to actual names\n",
    "df_labelconvertion.rename(columns={'Unnamed: 0': 'track_id', 'track.7': 'genre_top'}, inplace=True)\n",
    "\n",
    "# make df of only the important columns\n",
    "df_labelconvertion = df_labelconvertion[['track_id', 'genre_top']]\n",
    "\n",
    "# set all NA values to other \n",
    "df_labelconvertion['genre_top'] = df_labelconvertion['genre_top'].fillna('Other')\n",
    "\n",
    "# reset index from albums to normal index\n",
    "df_labelconvertion = df_labelconvertion.reset_index(drop=True)\n",
    "\n",
    "# make all values in the track_id column strings\n",
    "df_labelconvertion['track_id'] = df_labelconvertion['track_id'].astype(str)\n",
    "\n",
    "# remove first two rows\n",
    "df_labelconvertion = df_labelconvertion.iloc[2:]\n",
    "\n",
    "\n",
    "df_labelconvertion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5e3e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rock</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Experimental</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Folk</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jazz</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Spoken</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>International</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Soul-RnB</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Blues</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Country</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Classical</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Old-Time / Historic</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Instrumental</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Easy Listening</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  genre  number\n",
       "0               Hip-Hop       0\n",
       "1                   Pop       1\n",
       "2                 Other       2\n",
       "3                  Rock       3\n",
       "4          Experimental       4\n",
       "5                  Folk       5\n",
       "6                  Jazz       6\n",
       "7            Electronic       7\n",
       "8                Spoken       8\n",
       "9         International       9\n",
       "10             Soul-RnB      10\n",
       "11                Blues      11\n",
       "12              Country      12\n",
       "13            Classical      13\n",
       "14  Old-Time / Historic      14\n",
       "15         Instrumental      15\n",
       "16       Easy Listening      16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labelnumbers = pd.read_csv('fma_metadata/labelnumber.csv')\n",
    "\n",
    "df_labelnumbers.rename(columns={'Unnamed: 0': 'genre', '0': 'number'}, inplace=True)\n",
    "\n",
    "df_labelnumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "005d843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torch\n",
    "\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, file_paths, sr=44100, n_fft=1024, hop_length=512, window='hann', transform=None):\n",
    "        self.sr = sr\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.window = window\n",
    "        self.transform = transform\n",
    "        self.file_paths = file_paths\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        y, sr = librosa.load(file_path, sr=self.sr, mono = True)\n",
    "        y = y[:10 * self.sr]\n",
    "        D = librosa.stft(y, n_fft=self.n_fft, hop_length=self.hop_length, window=self.window)\n",
    "        D_real = np.real(D)\n",
    "        D_imag = np.imag(D)\n",
    "        D_real = torch.tensor(D_real, dtype=torch.float32)\n",
    "        D_imag = torch.tensor(D_imag, dtype=torch.float32)\n",
    "        \n",
    "        # concat real and imaginary parts to 2 channels\n",
    "        D = torch.stack((D_real, D_imag), dim=0)\n",
    "        # get the label from the file name and convert to genre\n",
    "        track_id = os.path.basename(file_path).replace('.mp3', '').lstrip('0')\n",
    "        # try to get the label from the dataframe\n",
    "        try:\n",
    "            # label = df_labelconvertion.query('track_id == @track_id')['genre_top'].values[0]\n",
    "            label = df_labelconvertion.query('track_id == @track_id')['genre_top'].values[0]\n",
    "            label = torch.tensor(df_labelnumbers.query('genre == @label')['number'].values[0])\n",
    "        except IndexError:\n",
    "            # if not found, set label to 'Other'\n",
    "            print(f\"Track ID: {track_id} not found in dataframe\")\n",
    "            label = 'Other'\n",
    "        \n",
    "        return D, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e7936cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "file_directory = 'fma_small'\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# get all file paths\n",
    "file_paths = []\n",
    "for root, _, files in os.walk(file_directory):\n",
    "    for file in files:\n",
    "        if file.endswith('.mp3'):\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "            \n",
    "# split the file paths into train and test\n",
    "train_paths, test_paths = train_test_split(file_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_dataset = SpectrogramDataset(train_paths)\n",
    "test_dataset = SpectrogramDataset(test_paths)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0e1976e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 513, 862])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# check the shape of the data\n",
    "for batch in train_dataloader:\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e5d498d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type     | Params\n",
      "-----------------------------------\n",
      "0 | model | ConvCVAE | 354 M \n",
      "-----------------------------------\n",
      "354 M     Trainable params\n",
      "0         Non-trainable params\n",
      "354 M     Total params\n",
      "1,416.368 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbac1027747e4416ab44dd5016ce743b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_maps shape torch.Size([32, 10, 513, 862])\n",
      "x shape torch.Size([32, 2, 513, 862])\n",
      "y_maps shape torch.Size([32, 10, 513, 862])\n",
      "x shape torch.Size([32, 2, 513, 862])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca1deb1d9f043d5a91c05010b2e429e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_maps shape torch.Size([32, 10, 513, 862])\n",
      "x shape torch.Size([32, 2, 513, 862])\n",
      "y_maps shape torch.Size([32, 10, 513, 862])\n",
      "x shape torch.Size([32, 2, 513, 862])\n",
      "Training finished\n",
      "Training time: 132.04594111442566 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "import cvae_actual_i_think\n",
    "import importlib\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "importlib.reload(cvae_actual_i_think) # Reload the cvae module to ensure it's up to date\n",
    "\n",
    "model = cvae_actual_i_think.ConvCVAEPL()\n",
    "\n",
    "# print(hasattr(model, 'forward'))\n",
    "\n",
    "logger = CSVLogger(\"logs\", name=\"train_10_epochs\")\n",
    "\n",
    "# Initialize the PyTorch Lightning Trainer\n",
    "trainer = Trainer(max_epochs=5, accelerator=\"auto\", logger=logger) #TODO\n",
    "\n",
    "\n",
    "# Train the model\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Training started\")\n",
    "\n",
    "trainer.fit(model, train_dataloader, test_dataloader)\n",
    "print(\"Training finished\")\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
